# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nuNjy8Bb--x9li9W6uYD8WoOH98-m4up
"""

!pip install kaggle # 케글 데이터 설치

# kaggle.json 파일 코렙드라이브로 마운팅하기
from google.colab import files 
files.upload()

"""캐글 로그인"""

# 케글 파일 만들기
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/

# Permission Warning 이 일어나지 않도록 
!chmod 600 ~/.kaggle/kaggle.json

# 케글 제이슨 파일 제대로 설치 됬는지 확인
!ls -lha kaggle.json # kaggle.json 이렇게

"""케글 파일 만들기"""

! kaggle competitions list

! kaggle datasets download -d meowmeowmeowmeowmeow/gtsrb-german-traffic-sign

!unzip gtsrb-german-traffic-sign.zip # zip 파일 풀기

"""traffic sign 캐글에서 다운로드"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np

import os
import pathlib

import cv2 
from PIL import Image 
from tensorflow.keras.preprocessing import image

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator 
from tensorflow.keras.preprocessing.image import img_to_array, array_to_img, load_img
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout
from tensorflow.keras.models import Sequential

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

import matplotlib.pyplot as plt
from matplotlib import style

np.random.seed(42)

# %matplotlib inline

"""필요한것들 임폴트"""

data_dir = pathlib.Path('/content/Meta')
train_path = pathlib.Path('/content/Train')
test_path = pathlib.Path('/content/Test')


IMG_HEGHT = 30
IMG_WIDTH = 30
channels = 3


NUM_CATEGORIES = len(os.listdir(train_path))
NUM_CATEGORIES

"""경로 설정,이미지 높이 30 넓이 30 색은 컬러로,카테고리 확인"""

folders = os.listdir('/content/train')
train_num = []
class_num = []

for folder in folders:
  train_files = os.listdir(str(train_path) + '/'+ folder) 
  train_num.append(len(train_files))
  class_num.append(classes[int(folder)])


zipped_lists =  zip(train_num, class_num)
sorted_pairs = sorted(zipped_lists)
tuples =  zip(*sorted_pairs) 
train_num, class_num = [ list(tuple) for tuple in tuples]

"""데이터 셋 분류,데이터 정렬해서 리스트 반환"""

def load_data(data_dir):
    images = list()
    labels = list()
    for category in range(NUM_CATEGORIES):
        categories = os.path.join(data_dir, str(category))
        for img in os.listdir(categories):
            img = load_img(os.path.join(categories, img), target_size=(30, 30))
            image = img_to_array(img) # 이미지를 넘파이 배열로 변환
            images.append(image) 
            labels.append(category)
    
    return images, labels
    
images, labels = load_data(train_path)

labels = to_categorical(labels)

x_train, x_test, y_train, y_test = train_test_split(np.array(images), labels, test_size=0.4)

"""넘파이 배열로 변환,원 핫 인코딩, split"""

model = Sequential()

IMG_HEIGHT = 30
IMG_WIDTH = 30

model.add(Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=(IMG_HEIGHT,IMG_WIDTH,3)))
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.25)) 

model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.25)) 

model.add(Conv2D(filters=80, kernel_size=2, activation='relu'))


model.summary()

"""학습 :컨볼브계층 3개 활성화 함수는 relu"""

# Flattening the layer and adding Dense Layer
model.add(Flatten())
model.add(Dense(units=64, activation='relu'))
model.add(Dense(NUM_CATEGORIES, activation='softmax'))

model.summary()

"""Flatten 후 출력층에서 활성화 함수 softmax"""

model.compile(
    loss='categorical_crossentropy', 
    optimizer='adam',                 
    metrics=['accuracy']
)


EPOCHS = 30
history = model.fit(x_train, 
                    y_train,
                    validation_data = (x_test, y_test), 
                    epochs=EPOCHS, 
                    steps_per_epoch=60
                   )

"""모델 컴파일,모델 핏,loss함수 cee,optimizer는 adam"""

loss, accuracy = model.evaluate(x_test, y_test)

print('test set accuracy: ', accuracy * 100)

"""테스트셋으로 테스트 한 결과 97퍼의 정확도를 보였다."""

Y_test = pd.read_csv('/content/Test.csv')
test_labels = Y_test["ClassId"].values
test_images = Y_test["Path"].values

a =  pathlib.Path('/content/')

output = list()
for img in test_images:
    image = load_img(os.path.join(a, img), target_size=(30, 30))
    output.append(np.array(image))

X_test=np.array(output)
y_prob = model.predict(X_test)
pred = y_prob.argmax(axis=-1)

#Accuracy with the test data
print('Test Data accuracy: ',accuracy_score(test_labels, pred)*100)

plt.figure(figsize = (13, 13))

start_index = 0
for i in range(25):
    plt.subplot(5, 5, i + 1)
    plt.grid(False)
    plt.xticks([])
    plt.yticks([])
    prediction = pred[start_index + i]
    actual = test_labels[start_index + i]
    col = 'g'
    if prediction != actual:
        col = 'r'
    plt.xlabel('actual={} || perdiction={}'.format(actual, prediction), color = col)
    plt.imshow(X_test[start_index + i])
plt.show()

"""25개중 23개 예측 성공"""

model.save('traffic_sign.h5')

"""모델 저장"""

